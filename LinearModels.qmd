---
format: 
  live-html:
    toc: true

execute:
  echo: true
  warning: false
  message: false

editor: 
  markdown: 
    wrap: 72
    
embed-resources: true
custom-callout:    
  example:
    icon-symbol: "üìù"
    color: "blue"


filters:
  - custom-callout
---

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

# An introduction to linear statistical models

-   Statistical modelling involves characteristing the relationship
    between predictors (X) and outcomes (Y).
    -   $$
        Y=f(X)+\varepsilon
        $$
-   $f(X)$ is a deterministic function and $\varepsilon$ is a 'random
    error' term

## A simple linear model

### Linear prediction

-   Assume that $f(X)$ is a linear function

    -   $$
        f(X)= \beta_0 + \beta_1\cdot X
        $$

-   putting aside the error term for now, the approximate value - lets
    call it the 'expected value' of Y, $E[Y]$, for now - can be
    represented by a linear equation,

    -   $$
        E[Y]= \beta_0 + \beta_1\cdot X
        $$

-   or alternatively as a line with y-intercept $\beta_0$ and slope
    $\beta_1$:

    -   (interactive plot with control over beta)

-   That is, $\beta_0$ tells us what Y looks like when $X=0$, and
    $\beta_1$ tells us how much Y changes when X increases by 1.

::: example
-   given model verbally
-   Exercises:
  -   specify beta
  -   calculate (predict) E\[Y\] given X
  -   (more advanced R task?) complete the R function that takes a vector
      of Xs and outputs Ys (then call that function)
:::

### random variation

-   Data rarely lie perfectly on a line (variance)
    -   Add error term ( \varepsilon ):\
        $$y = \beta_0 + \beta_1 x + \varepsilon$$
-   Assume
    -   $$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$
    
::: example
-   Same model as above - given standard deviation 
-   Example Y values
    -   Illustrate error with normal overay
-   Excersises:
    - which variance is larger?
    - (hard) probability of finding E[Y]+2sd observation

:::
